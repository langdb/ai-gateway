guards:
  - type: llm_judge
    id: toxicity-1
    name: Toxicity Detection
    definition_id: toxicity
    definition_name: Toxicity Detection
    description: Detects toxic, harmful, or inappropriate content
    stage: output
    action: validate
    model: gpt-3.5-turbo
    system_prompt: You are a content moderator tasked with identifying toxic, harmful, or inappropriate content.
    user_prompt_template: >
      Please analyze the following text and determine if it contains toxic, harmful, or inappropriate content. Return a JSON object with a "toxic" boolean field and a "confidence" number field between 0 and 1. Text to analyze: {{text}}
    parameters:
      threshold: 0.7
      categories:
        - hate
        - harassment
        - violence
        - self-harm
        - sexual
        - profanity
      evaluation_criteria:
        - Hate speech
        - Harassment
        - Violence
        - Self-harm
        - Sexual content
        - Profanity

  - type: schema
    id: schema-chat-1
    name: Chat Message Schema
    definition_id: schema-chat
    definition_name: Chat Message Schema
    description: Validates that responses follow the chat message schema
    stage: output
    action: validate
    schema:
      type: object
      required:
        - message
      properties:
        message:
          type: string
          minLength: 1
        sentiment:
          type: string
          enum:
            - positive
            - neutral
            - negative

  - type: llm_judge
    id: competitor-1
    name: Competitor Mention Check
    definition_id: competitor
    definition_name: Competitor Mention Check
    description: Detects mentions of competitor companies or products
    stage: output
    action: validate
    model: openai/gpt-3.5-turbo
    system_prompt: You are an assistant that identifies mentions of competitor companies or products.
    user_prompt_template: >
      Please analyze the following text and determine if it mentions any of these competitor names or products. Return a JSON object with a "mentions_competitor" boolean field and a "competitors_found" array of strings. Competitors to check for: {{competitors}}. Text to analyze: {{text}}
    parameters:
      competitors:
        - Competitor A
        - Competitor B
        - Competitor C
      match_partial: true
      case_sensitive: false

  - type: llm_judge
    id: pii-1
    name: PII Detection
    definition_id: pii
    definition_name: PII Detection
    description: Detects personally identifiable information
    stage: input
    action: validate
    model: openai/gpt-3.5-turbo
    system_prompt: You are a privacy protection assistant that identifies personally identifiable information (PII).
    user_prompt_template: >
      Please analyze the following text and identify if it contains any PII such as email addresses, phone numbers, social security numbers, or credit card numbers. Return a JSON object with a "contains_pii" boolean field and a "pii_types" array of strings. Text to analyze: {{text}}
    parameters:
      pii_types:
        - email
        - phone
        - ssn
        - credit_card
      redact: false

  # - type: dataset
  #   id: company-policy-1
  #   name: Company Policy Compliance
  #   definition_id: company-policy
  #   definition_name: Company Policy Compliance
  #   description: Checks if text complies with company policies
  #   stage: output
  #   action: validate
  #   embedding_model: text-embedding-ada-002
  #   threshold: 0.8
  #   dataset:
  #     type: examples
  #     examples:
  #       - text: "We offer a 30-day money-back guarantee on all our products."
  #         label: true
  #       - text: "We can't provide refunds under any circumstances."
  #         label: false
  #       - text: "Our company is committed to sustainability and environmental protection."
  #         label: true
  #       - text: "We don't care about environmental impact."
  #         label: false
